torch>=2.1.0
transformers>=4.36.0
datasets>=2.14.0
trl>=0.7.0
accelerate>=0.25.0
peft>=0.10.0
sentencepiece>=0.1.99
# flash-attn not required - using PyTorch native SDPA instead
